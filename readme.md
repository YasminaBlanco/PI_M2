# Proyecto Integrador: 

Este proyecto es una soluciÃ³n integral para el anÃ¡lisis de Key Performance Indicators (KPIs) de productos de un e-commerce. Combina un pipeline de datos robusto con una aplicaciÃ³n interactiva para visualizar mÃ©tricas clave y obtener insights sobre el rendimiento de los productos.

## ğŸ¯ Objetivos del Proyecto

Este Proyecto Integrador (PI) se ha desarrollado con los siguientes objetivos clave:

* **Identificar los datos necesarios** para responder preguntas de negocio a partir de una sÃ¡bana de datos a fin de cumplir los objetivos clave del negocio.
* **Utilizar SQL para realizar transformaciones de datos** utilizando la metodologÃ­a de transformaciÃ³n por capas o arquitectura tipo medallÃ³n.
* **Modelar datos utilizando modelado dimensional** y siguiendo buenas prÃ¡cticas de trabajo como recopilaciÃ³n de requisitos empresariales, definiciÃ³n de la granularidad, identificaciÃ³n de hechos e identificaciÃ³n de dimensiones.
* **DiseÃ±ar e implementar un modelo de datos dimensional** utilizando Slowly Changing Dimensions (SCDs) y gestionar las transformaciones con dbt.
* **DiseÃ±ar e implementar KPIs y mÃ©tricas** para identificar patrones que ayuden a responder las preguntas de negocio.

## ğŸš€ CaracterÃ­sticas Principales

* **ExtracciÃ³n y Carga de Datos:** Herramientas para cargar datos iniciales en la base de datos.
* **TransformaciÃ³n de Datos con dbt:** Modelos de datos definidos con dbt (Data Build Tool) para transformar datos crudos en mÃ©tricas de negocio listas para el anÃ¡lisis.
* **AnÃ¡lisis de KPIs:** CÃ¡lculo y seguimiento de mÃ©tricas como ingresos totales, crecimiento porcentual de ventas e intenciÃ³n de compra (productos agregados al carrito).
* **Dashboard Interactivo con Streamlit:** Una aplicaciÃ³n web intuitiva que permite a los usuarios explorar los KPIs, filtrar por mes y categorÃ­a, e identificar tendencias y oportunidades.
* **Conectividad con PostgreSQL:** Utiliza PostgreSQL como base de datos para almacenar y gestionar los datos.

## ğŸ› ï¸ TecnologÃ­as Utilizadas

* **Python:** Lenguaje principal para scripting, conectividad a la base de datos y la aplicaciÃ³n Streamlit.
* **Streamlit:** Framework para construir la aplicaciÃ³n interactiva del dashboard.
* **dbt (Data Build Tool):** Para la orquestaciÃ³n y transformaciÃ³n de datos en el almacÃ©n de datos.
* **PostgreSQL:** Sistema de gestiÃ³n de bases de datos relacionales.
* **Pandas:** Biblioteca para manipulaciÃ³n y anÃ¡lisis de datos en Python.
* **Altair:** Biblioteca de visualizaciÃ³n declarativa para Python, utilizada en Streamlit.
* **`.env`:** Para la gestiÃ³n segura de variables de entorno (credenciales de base de datos).
* **Docker / Docker Compose:** Para la contenerizaciÃ³n y orquestaciÃ³n de los servicios (base de datos, aplicaciÃ³n).

## ğŸ“‚ Estructura del Proyecto

```
â”œâ”€â”€ dbt_profiles/               # ConfiguraciÃ³n de perfiles de dbt
â”‚    â””â”€â”€ profiles.yml           # Perfil de dbt para la base de datos
â”œâ”€â”€ proyecto_dbt/               # Scripts de dbt para la base de datos
â”‚    â””â”€â”€ models/
â”‚           â””â”€â”€ bronze/
â”‚               â””â”€â”€ sources.yml # ConfiguraciÃ³n de fuentes de datos
â”‚               â””â”€â”€ stg.sql     # Modelos stg en .sql   
â”‚           â””â”€â”€ silver/
â”‚               â””â”€â”€ dim_productos.sql     # Modelos dim en .sql
â”‚               â””â”€â”€ dim_categorias.sql     # Modelos dim en .sql
â”‚               â””â”€â”€ fact_carritos.sql # Modelo de datos de carritos
â”‚               â””â”€â”€ fact_ordenes.sql # Modelo de datos de ordenes
â”‚               â””â”€â”€ fact_productos.sql # Modelo de datos de productos
â”‚           â””â”€â”€ gold/
â”‚               â””â”€â”€ agg_crecimiento_ventas_productos.sql    # Modelo de agregaciÃ³n de KPIs
â”‚               â””â”€â”€ agg_ingresos_productos.sql              # Modelo de agregaciÃ³n de KPIs
â”‚               â””â”€â”€ agg_intencion_compra_productos.sql      # Modelo de agregaciÃ³n de KPIs
â”‚               â””â”€â”€ rpt_analisis_productos_kpis.sql         # Modelo principal de KPIs
â”‚    â””â”€â”€ macros/        # Macros de dbt para test
â”‚    â””â”€â”€ snapshots/     # Snapshots de historial de cambios
â”‚    â””â”€â”€ readme.md      # Archivo de documentaciÃ³n para dbt
â”œâ”€â”€ init-scripts/               # Scripts SQL para inicializaciÃ³n de la base de datos
â”‚   â””â”€â”€ 01-EcommerceDB.sql      # Script de creaciÃ³n de esquema y tablas
â”œâ”€â”€ orm/                        # MÃ³dulo de Object-Relational Mapping y scripts de datos
â”‚   â”œâ”€â”€ cargar_datos.py         # Script para cargar datos en la DB
â”‚   â”œâ”€â”€ crear_tablas.py         # Script para crear tablas (si no se usa init-scripts)
â”‚   â”œâ”€â”€ db_conector.py          # MÃ³dulo de conexiÃ³n a la base de datos
â”‚   â”œâ”€â”€ exploracion_tablas.py   # Script para explorar las tablas de la base de datos
â”‚   â”œâ”€â”€ modelo_tablas.py        # DefiniciÃ³n de modelos de tablas
â”‚   â”œâ”€â”€ readme.md               # Archivo de documentaciÃ³n para el orm
â”œâ”€â”€ streamlit/                  # AplicaciÃ³n Streamlit
â”‚   â”œâ”€â”€ app.py                  # CÃ³digo principal de la aplicaciÃ³n Streamlit
â”‚   â”œâ”€â”€ Dockerfile              # Dockerfile para la aplicaciÃ³n Streamlit
â”‚   â””â”€â”€ requirements.txt        # Dependencias de Python para Streamlit
â”œâ”€â”€ docker-compose.yml          # ConfiguraciÃ³n de Docker Compose
â”œâ”€â”€ Dockerfile                  # Dockerfile para el proyecto
â””â”€â”€ README.md                   # Este archivo
```

## âš™ï¸ ConfiguraciÃ³n y EjecuciÃ³n (Orden de Pasos)

Para poner en marcha este proyecto, sigue los siguientes pasos en el orden indicado:

### 1. CreaciÃ³n de entorno virtual

```bash
python3 -m venv .venv
source .venv/bin/activate # En Linux/macOS
.venv\Scripts\activate   # En Windows
```

Luego, instala las dependencias generales del proyecto que estan en el archivo `requirements.txt` en la raÃ­z del proyecto, con los siguientes comandos:

```bash
pip install -r requirements.txt
```

### 2. Variables de Entorno

Copia el archivo `.env.example` a `.env` en la **raÃ­z del proyecto**, en la carpeta **`orm/`** y en la carpeta de **`streamlit/`** . Edita ambos archivos `.env` con tus credenciales de base de datos y otras configuraciones necesarias. 

```
# Ejemplo de .env.example
DB_HOST=your_db_host
DB_NAME=your_db_name
DB_USER=your_db_user
DB_PASSWORD=your_db_password
DB_PORT=your_db_port

PGADMIN_DEFAULT_EMAIL=your_pgadmin_email
PGADMIN_DEFAULT_PASSWORD=your_pgadmin_password

DBT_PROFILES_DIR=/root/.dbt
```

### 3. Levantamiento de la Base de Datos con Docker

AsegÃºrate de tener Docker y Docker Compose instalados. Desde la raÃ­z del proyecto, levanta los contenedores definidos en `docker-compose.yml`. Esto iniciarÃ¡ tu base de datos PostgreSQL
y crearÃ¡ los contenedores de dbt (la carpeta `proyecto_dbt/`) y Streamlit.

```bash
docker-compose up --build -d
```
Verifica que el contenedor de la base de datos (`db`) estÃ© en ejecuciÃ³n.

### 4 ğŸ‘‰[ConfiguraciÃ³n y Carga de Datos Iniciales](orm/readme.md)ğŸ‘ˆ (hacer click para ir a la secciÃ³n)

Esta secciÃ³n se encarga de preparar la base de datos y cargar los datos iniciales.

* **CreaciÃ³n de Tablas:** Ejecutar el script `crear_tablas.py` para definir el esquema de tu base de datos.
    ```bash
    cd orm
    python crear_tablas.py
    ```
* **Carga de Datos:** Ejecuta el script `cargar_datos.py` para poblar la base de datos con los datos iniciales necesarios.
    ```bash
    python cargar_datos.py
    ```

### 5. ğŸ‘‰[EjecuciÃ³n de Modelos dbt](proyecto_dbt/readme.md)ğŸ‘ˆ (hacer click para ir a la secciÃ³n)

Una vez que la base de datos estÃ© poblada, navega al contenedor desde la consola bash para transformar tus datos.
Con los siguientes comandos:
```bash
docker exec -it dbt_container bash
cd ecommerce
dbt init ecommerce_project
```
* Llenar las carpeta de models, macros, snapshots con los script propuestos en la carpeta `project_dbt/` luego de ejecutar los siguientes comandos:

```bash
dbt deps
dbt compile
dbt snapshot
dbt debug
dbt run --full-refresh
dbt test
dbt docs generate
dbt docs serve
```

### 6. EjecuciÃ³n de la AplicaciÃ³n Streamlit

La aplicaciÃ³n Streamlit se iniciarÃ¡ automÃ¡ticamente como parte de la orquestaciÃ³n de contenedores. PodrÃ¡s acceder al dashboard en tu navegador normalmente `http://localhost:8501`.
